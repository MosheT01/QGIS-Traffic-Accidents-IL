{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2014 - Accident Data: H20141332Accdatamekuzar.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2014000001        1              1          1          7400   303.0   \n",
      "1     2014000002        1              1          2          2650   390.0   \n",
      "2     2014000003        1              1          4             0     NaN   \n",
      "3     2014000004        1              1          1          5000  1555.0   \n",
      "4     2014000006        1              1          2          7600   505.0   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  \\\n",
      "0   306.0     NaN     260021.0     NaN  ...             3             1   \n",
      "1     NaN  9999.0          NaN     NaN  ...             3             9   \n",
      "2     NaN     NaN          NaN    20.0  ...             2             2   \n",
      "3  1511.0     NaN   11920611.0     NaN  ...             3             1   \n",
      "4     NaN    19.0          NaN     NaN  ...             3             1   \n",
      "\n",
      "   MAHOZ  NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN  \\\n",
      "0      4    41        411                0.0           13            1   \n",
      "1      5    51        511                0.0           16            3   \n",
      "2      5    53        513               99.0           99            1   \n",
      "3      5    51        511                0.0           13            1   \n",
      "4      2    24        246                0.0           16            1   \n",
      "\n",
      "          X         Y  \n",
      "0  187117.0  693833.0  \n",
      "1  185113.0  672015.0  \n",
      "2  177520.0  659502.0  \n",
      "3  179727.0  663713.0  \n",
      "4  207503.0  759266.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2014 - Accident Data: H20141332Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2014 - Traffic Count Data: 2014109h1tabmef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2014      1    10       1       9        7    1     0   1936     NaN\n",
      "1   2014      1    10       1       9        7    1     1    966     NaN\n",
      "2   2014      1    10       1       9        7    1     2    737     NaN\n",
      "3   2014      1    10       1       9        7    1     3    596     NaN\n",
      "4   2014      1    10       1       9        7    1     4    479     NaN\n",
      "\n",
      "\n",
      "Year 2014 - Traffic Count Data: h20141091roadsnonurban.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3',\n",
      "       'ספירות תנועה 2014 PUF', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'],\n",
      "      dtype='object')\n",
      "  Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3       ספירות תנועה 2014 PUF  \\\n",
      "0        NaN        NaN        NaN        NaN  מילון קטעי דרך לא-עירוניים   \n",
      "1        NaN        NaN        NaN        NaN                         NaN   \n",
      "2        NaN        NaN        NaN        NaN                         NaN   \n",
      "3        NaN        NaN        NaN        NaN                         NaN   \n",
      "4        NaN        NaN        NaN        NaN                         NaN   \n",
      "\n",
      "  Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN  \n",
      "\n",
      "\n",
      "Year 2015 - Accident Data: H20151332Accdatamekuzar.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2015000000        1              1          4             0     NaN   \n",
      "1     2015000022        1              1          2          8300  6003.0   \n",
      "2     2015000035        1              1          1          9000   102.0   \n",
      "3     2015000038        1              1          2          9100   409.0   \n",
      "4     2015000043        1              1          2          7300   118.0   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  \\\n",
      "0     NaN     NaN          NaN     NaN  ...             0             9   \n",
      "1     NaN  9999.0          NaN     NaN  ...             0             9   \n",
      "2   101.0     NaN     150021.0     NaN  ...             1             2   \n",
      "3     NaN     6.0          NaN     NaN  ...             0             9   \n",
      "4     NaN  9999.0          NaN     NaN  ...             0             9   \n",
      "\n",
      "   MAHOZ  NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN  \\\n",
      "0      9    99        999               99.0           99            9   \n",
      "1      4    44        442                0.0           13            3   \n",
      "2      6    62        623                0.0           13            1   \n",
      "3      2    24        245                0.0           15            1   \n",
      "4      2    23        237                0.0           25            3   \n",
      "\n",
      "          X         Y  \n",
      "0       NaN       NaN  \n",
      "1  181911.0  654345.0  \n",
      "2  182702.0  573212.0  \n",
      "3  209441.0  767370.0  \n",
      "4  229395.0  734603.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2015 - Accident Data: H20151332Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2015 - Traffic Count Data: H20151091RoadsNonUrban.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3',\n",
      "       'ספירות תנועה 2015 PUF', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'],\n",
      "      dtype='object')\n",
      "  Unnamed: 0 Unnamed: 1 Unnamed: 2         Unnamed: 3  \\\n",
      "0        NaN        NaN        NaN                NaN   \n",
      "1      kvish       keta      km_me         shem_km_me   \n",
      "2          1         10          0  מחלף קיבוץ גלויות   \n",
      "3          1         52       18.9        מחלף בן שמן   \n",
      "4          1         56         25          מחלף ענבה   \n",
      "\n",
      "        ספירות תנועה 2015 PUF  Unnamed: 5 Unnamed: 6             Unnamed: 7  \n",
      "0  מילון קטעי דרך לא-עירוניים         NaN        NaN                    NaN  \n",
      "1                       ad_km  shem_km_ad  km_hazava            teur_hazava  \n",
      "2                         4.6   מחלף גנות        4.5          ליד צומת גנות  \n",
      "3                          25   מחלף ענבה         24  בקילומטר העשרים וארבע  \n",
      "4                        33.6  מחלף לטרון         26              גלאי קבוע  \n",
      "\n",
      "\n",
      "Year 2015 - Traffic Count Data: H20151091TabMef_1.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2015      1    10       1       6       15    2     0   1346     NaN\n",
      "1   2015      1    10       1       6       15    2     1    788     NaN\n",
      "2   2015      1    10       1       6       15    2     2    626     NaN\n",
      "3   2015      1    10       1       6       15    2     3    652     NaN\n",
      "4   2015      1    10       1       6       15    2     4    597     NaN\n",
      "\n",
      "\n",
      "Year 2015 - Traffic Count Data: H20151091TabMef_2.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2015    222    10       0       2       17    3     0     39     NaN\n",
      "1   2015    222    10       0       2       17    3     1     20     NaN\n",
      "2   2015    222    10       0       2       17    3     2     14     NaN\n",
      "3   2015    222    10       0       2       17    3     3     16     NaN\n",
      "4   2015    222    10       0       2       17    3     4      9     NaN\n",
      "\n",
      "\n",
      "Year 2016 - Accident Data: H20161332Accdatamekuzar.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2016000001        1              1          1          5000   714.0   \n",
      "1     2016000008        1              1          2          3000  5405.0   \n",
      "2     2016000014        1              1          2          8300   975.0   \n",
      "3     2016000020        1              1          1          9100   458.0   \n",
      "4     2016000024        1              1          2          7400   847.0   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  \\\n",
      "0   720.0     NaN   80150504.0     NaN  ...             0             9   \n",
      "1     NaN     4.0          NaN     NaN  ...             0             9   \n",
      "2     NaN  9999.0          NaN     NaN  ...             0             9   \n",
      "3   467.0     NaN    8850006.0     NaN  ...             0             9   \n",
      "4     NaN  9999.0          NaN     NaN  ...             0             9   \n",
      "\n",
      "   MAHOZ  NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN  \\\n",
      "0      5    51        511                0.0           13            1   \n",
      "1      1    11        111                0.0           12            3   \n",
      "2      4    44        442                0.0           13            3   \n",
      "3      2    24        245                0.0           15            1   \n",
      "4      4    41        411                0.0           13            3   \n",
      "\n",
      "          X         Y  \n",
      "0  179175.0  665225.0  \n",
      "1  221605.0  629186.0  \n",
      "2  175161.0  656287.0  \n",
      "3  208922.0  766064.0  \n",
      "4  188386.0  690385.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2016 - Accident Data: H20161332Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2016 - Traffic Count Data: H20161091RoadsNonUrban.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['כביש', 'קטע', 'ק\"מ מ-', 'שם מ-', 'ק\"מ עד', 'שם עד', 'ק\"מ הצבה', 'הצבה',\n",
      "       'X של מקום ההצבה', 'Y של מקום ההצבה'],\n",
      "      dtype='object')\n",
      "   כביש  קטע  ק\"מ מ-              שם מ-  ק\"מ עד            שם עד  ק\"מ הצבה  \\\n",
      "0     1   10     0.0  מחלף קיבוץ גלויות    46.0        מחלף גנות      45.0   \n",
      "1     1   52   189.0        מחלף בן שמן   250.0        מחלף ענבה     231.0   \n",
      "2     1   56   250.0          מחלף ענבה   336.0       מחלף לטרון     260.0   \n",
      "3     1   60   336.0         מחלף לטרון   385.0    מחלף שער הגיא     365.0   \n",
      "4     2   70   617.0        מחלף קיסריה   755.0  מחלף זכרון יעקב     682.0   \n",
      "\n",
      "                    הצבה  X של מקום ההצבה  Y של מקום ההצבה  \n",
      "0          ליד צומת גנות              NaN              NaN  \n",
      "1  בקילומטר העשרים ושלוש         193638.0         647061.0  \n",
      "2              גלאי קבוע              NaN              NaN  \n",
      "3   2.92 ק\"מ ממחלף לטרון         200817.0         636966.0  \n",
      "4  6.53 ק\"מ ממחלף קיסריה         192262.0         714572.0  \n",
      "\n",
      "\n",
      "Year 2016 - Traffic Count Data: H20161091TabMef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2016      1    10       1       9       11    1     0   1710     NaN\n",
      "1   2016      1    10       1       9       11    1     1    934     NaN\n",
      "2   2016      1    10       1       9       11    1     2    800     NaN\n",
      "3   2016      1    10       1       9       11    1     3    637     NaN\n",
      "4   2016      1    10       1       9       11    1     4    588     NaN\n",
      "\n",
      "\n",
      "Year 2017 - Accident Data: H20171332AccdataMEKUZAR.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2017000013        1              1          4             0     NaN   \n",
      "1     2017000015        1              1          2          8300  1200.0   \n",
      "2     2017000030        1              1          1          4000   210.0   \n",
      "3     2017000044        1              1          2          5000  2524.0   \n",
      "4     2017000064        1              1          2          8600   903.0   \n",
      "\n",
      "   REHOV2  BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  MAHOZ  \\\n",
      "0     NaN    NaN          NaN   461.0  ...             0             9      4   \n",
      "1     NaN   18.0          NaN     NaN  ...             3             9      4   \n",
      "2   203.0    NaN     180131.0     NaN  ...             0             9      3   \n",
      "3     NaN  126.0          NaN     NaN  ...             0             9      5   \n",
      "4     NaN   60.0          NaN     NaN  ...             0             9      5   \n",
      "\n",
      "   NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN         X  \\\n",
      "0    42        422               99.0           99            1  188576.0   \n",
      "1    44        442                0.0           13            1  178907.0   \n",
      "2    31        311                0.0           13            1  206413.0   \n",
      "3    51        511                0.0           13            1  180853.0   \n",
      "4    51        512                0.0           14            1  183405.0   \n",
      "\n",
      "          Y  \n",
      "0  659626.0  \n",
      "1  652870.0  \n",
      "2  746463.0  \n",
      "3  664685.0  \n",
      "4  666132.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2017 - Accident Data: H20171332Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2017 - Traffic Count Data: h20171092roadsnonurban.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['כביש', 'קטע', 'ק\"מ מ-', 'שם מ-', 'ק\"מ עד', 'שם עד', 'ק\"מ הצבה', 'הצבה',\n",
      "       'X של מקום ההצבה', 'Y של מקום ההצבה'],\n",
      "      dtype='object')\n",
      "   כביש  קטע  ק\"מ מ-                        שם מ-  ק\"מ עד            שם עד  \\\n",
      "0     1   52    18.9                  מחלף בן שמן    25.0        מחלף ענבה   \n",
      "1     1   56    25.0                    מחלף ענבה    33.6       מחלף לטרון   \n",
      "2     1  872    64.0  כניסה לדרך האלוף עוזי נרקיס    74.7      מחלף אדומים   \n",
      "3     2   52    43.8                   מחלף נתניה    51.0        מחלף ינאי   \n",
      "4     2   70    61.7                  מחלף קיסריה    75.5  מחלף זכרון יעקב   \n",
      "\n",
      "   ק\"מ הצבה                               הצבה  X של מקום ההצבה  \\\n",
      "0      23.1              בקילומטר העשרים ושלוש         193645.0   \n",
      "1      26.0                          גלאי קבוע              NaN   \n",
      "2      70.3  5.69 ק\"מ מדר' מעלה אדומים שד' משה         225579.0   \n",
      "3      49.4                1.63 ק\"מ ממחלף ינאי         187331.0   \n",
      "4      68.2              6.53 ק\"מ ממחלף קיסריה         192262.0   \n",
      "\n",
      "   Y של מקום ההצבה  \n",
      "0         647061.0  \n",
      "1              NaN  \n",
      "2         632400.0  \n",
      "3         697092.0  \n",
      "4         714572.0  \n",
      "\n",
      "\n",
      "Year 2017 - Traffic Count Data: h20171092tabmef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2017      1    52       1       2        5    1     0    839     NaN\n",
      "1   2017      1    52       1       2        5    1     1    459     NaN\n",
      "2   2017      1    52       1       2        5    1     2    338     NaN\n",
      "3   2017      1    52       1       2        5    1     3    318     NaN\n",
      "4   2017      1    52       1       2        5    1     4    403     NaN\n",
      "\n",
      "\n",
      "Year 2018 - Accident Data: h20181331accdatwebsite.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2018000004        1              1          1           841   104.0   \n",
      "1     2018000018        1              1          1          4000   896.0   \n",
      "2     2018000030        1              1          1          7100  1035.0   \n",
      "3     2018000037        1              1          4             0     NaN   \n",
      "4     2018000049        1              1          3             0     NaN   \n",
      "\n",
      "   REHOV2  BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  MAHOZ  \\\n",
      "0   105.0    NaN          2.0     NaN  ...             0             9      4   \n",
      "1   825.0    NaN   10210522.0     NaN  ...             0             9      3   \n",
      "2   496.0    NaN   10800341.0     NaN  ...             0             9      6   \n",
      "3     NaN    NaN          NaN    91.0  ...             0             9      9   \n",
      "4     NaN    NaN          NaN     4.0  ...             0             9      9   \n",
      "\n",
      "   NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN         X  \\\n",
      "0    42        421               20.0           31            1  193498.0   \n",
      "1    31        311                0.0           13            1  200041.0   \n",
      "2    61        614                0.0           14            1  161755.0   \n",
      "3    99        999               99.0           99            1  258984.0   \n",
      "4    99        999               99.0           99            1  203320.0   \n",
      "\n",
      "          Y  \n",
      "0  673585.0  \n",
      "1  746160.0  \n",
      "2  620861.0  \n",
      "3  768332.0  \n",
      "4  743957.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2018 - Accident Data: h20181331dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2018 - Traffic Count Data: 2018109H1TabMef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'nefah', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2018      1    54       1       6       14    5     0   1018     NaN\n",
      "1   2018      1    54       1       6       14    5     1    814     NaN\n",
      "2   2018      1    54       1       6       14    5     2    450     NaN\n",
      "3   2018      1    54       1       6       14    5     3    415     NaN\n",
      "4   2018      1    54       1       6       14    5     4    471     NaN\n",
      "\n",
      "\n",
      "Year 2020 - Accident Data: H20201331Data.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2019047557        1              1          1          2620   173.0   \n",
      "1     2019061987        1              1          2          6500   941.0   \n",
      "2     2019081420        1              1          2          6600   706.0   \n",
      "3     2019095567        1              1          1          6600   706.0   \n",
      "4     2020000003        1              1          3             0     NaN   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  \\\n",
      "0   283.0     NaN   10780001.0     NaN  ...             0             9   \n",
      "1     NaN  9999.0          NaN     NaN  ...             0             9   \n",
      "2     NaN    50.0          NaN     NaN  ...             3             9   \n",
      "3   708.0     NaN    8360033.0     NaN  ...             3             2   \n",
      "4     NaN     NaN          NaN   461.0  ...             0             9   \n",
      "\n",
      "   MAHOZ  NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN  \\\n",
      "0      5    51        512                0.0         16.0            1   \n",
      "1      3    32        324                0.0         15.0            3   \n",
      "2      5    51        513                0.0         14.0            1   \n",
      "3      5    51        513                0.0         14.0            1   \n",
      "4      5    52        512               99.0         99.0            1   \n",
      "\n",
      "          X         Y  \n",
      "0  185530.0  663581.0  \n",
      "1  194561.0  704174.0  \n",
      "2  178996.0  658800.0  \n",
      "3  178992.0  658769.0  \n",
      "4  185093.0  660450.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2020 - Accident Data: H20201331Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2020 - Traffic Count Data: H20201091TabMef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shana', 'kvish', 'keta', 'maslul', 'hodesh', 'taarich', 'yom', 'shaa',\n",
      "       'kamut', 'status'],\n",
      "      dtype='object')\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  kamut  status\n",
      "0   2020      1    20       1      12        2    4     0   1123     NaN\n",
      "1   2020      1    20       1      12        2    4     1    557     NaN\n",
      "2   2020      1    20       1      12        2    4     2    376     NaN\n",
      "3   2020      1    20       1      12        2    4     3    300     NaN\n",
      "4   2020      1    20       1      12        2    4     4    376     NaN\n",
      "\n",
      "\n",
      "Year 2021 - Accident Data: H20211041Dictionary.csv\n",
      "Accident Data Columns:\n",
      "Index(['MS_TAVLA', 'KOD', 'TEUR'], dtype='object')\n",
      "   MS_TAVLA  KOD           TEUR\n",
      "0         0    1  יחידה משטרתית\n",
      "1         0    2       סוג הדרך\n",
      "2         0    4   חומרת התאונה\n",
      "3         0    5     סוג התאונה\n",
      "4         0    9      צורת הדרך\n",
      "\n",
      "\n",
      "Year 2021 - Accident Data: puf Äùàûÿ.csv\n",
      "Accident Data Columns:\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'KVISH1',\n",
      "       'KVISH2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA',\n",
      "       'HODESH_TEUNA', 'SHAA', 'SUG_YOM', 'YOM_LAYLA', 'YOM_BASHAVUA',\n",
      "       'HUMRAT_TEUNA', 'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL',\n",
      "       'MEHIRUT_MUTERET', 'TKINUT', 'ROHAV', 'SIMUN_TIMRUR', 'TEURA',\n",
      "       'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM', 'MERHAK_EZEM', 'LO_HAZA',\n",
      "       'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA', 'MAHOZ', 'NAFA',\n",
      "       'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV', 'STATUS_IGUN', 'X',\n",
      "       'Y'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2020031644        1              1          1          1061   159.0   \n",
      "1     2020079871        1              1          4             0     NaN   \n",
      "2     2020081980        1              1          1          3000  1105.0   \n",
      "3     2021000007        1              1          1          4000  1394.0   \n",
      "4     2021000010        1              1          3             0     NaN   \n",
      "\n",
      "   REHOV2  BAYIT  ZOMET_IRONI  KVISH1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  MAHOZ  \\\n",
      "0   275.0    NaN    7840004.0     NaN  ...             3             1      2   \n",
      "1     NaN    NaN          NaN  8966.0  ...             0             9      2   \n",
      "2  1307.0    NaN   26640236.0     NaN  ...             0             9      1   \n",
      "3  1391.0    NaN   17000742.0     NaN  ...             0             9      3   \n",
      "4     NaN    NaN          NaN    89.0  ...             0             9      2   \n",
      "\n",
      "   NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN         X  \\\n",
      "0    23        237                0.0           16            1  230441.0   \n",
      "1    21        212               99.0           99            1  245802.0   \n",
      "2    11        111                0.0           12            1  218356.0   \n",
      "3    31        311                0.0           13            1  201379.0   \n",
      "4    45        245               99.0           99            1  216335.0   \n",
      "\n",
      "          Y  \n",
      "0  734148.0  \n",
      "1  772308.0  \n",
      "2  629343.0  \n",
      "3  742666.0  \n",
      "4  768965.0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "\n",
      "Year 2021 - Traffic Count Data: H20211092TabMef.csv\n",
      "Traffic Count Data Columns:\n",
      "Index(['shnat_seker', 'kvish', 'keta', 'maslul', 'hodesh', 'yom',\n",
      "       'yom_bashavua', 'shaa', 'kamut_kle_rehev', 'status_reshuma'],\n",
      "      dtype='object')\n",
      "   shnat_seker  kvish  keta  maslul  hodesh  yom  yom_bashavua  shaa  \\\n",
      "0       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   0.0   \n",
      "1       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   1.0   \n",
      "2       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   2.0   \n",
      "3       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   3.0   \n",
      "4       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   4.0   \n",
      "\n",
      "   kamut_kle_rehev  status_reshuma  \n",
      "0           1486.0             NaN  \n",
      "1           1170.0             NaN  \n",
      "2            795.0             NaN  \n",
      "3            601.0             NaN  \n",
      "4           1134.0             NaN  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory for the data\n",
    "base_dir = os.path.abspath('../')  # Adjusted to correct path\n",
    "# Function to check the structure of accident and traffic count data for each year\n",
    "def check_data_structure(year):\n",
    "    # Define paths to accident and traffic count data\n",
    "    accident_path = os.path.join(base_dir, year, 'accidents')\n",
    "    traffic_path = os.path.join(base_dir, year, 'count')\n",
    "    \n",
    "    try:\n",
    "        # Load accident data\n",
    "        accident_files = [f for f in os.listdir(accident_path) if f.endswith('.csv')]\n",
    "        for file in accident_files:\n",
    "            print(f\"Year {year} - Accident Data: {file}\")\n",
    "            accident_df = pd.read_csv(os.path.join(accident_path, file), encoding='ISO-8859-8')\n",
    "            print(\"Accident Data Columns:\")\n",
    "            print(accident_df.columns)\n",
    "            print(accident_df.head())\n",
    "            print(\"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Accident data folder not found for year {year}\")\n",
    "    \n",
    "    try:\n",
    "        # Load traffic count data\n",
    "        traffic_files = [f for f in os.listdir(traffic_path) if f.endswith('.csv')]\n",
    "        for file in traffic_files:\n",
    "            print(f\"Year {year} - Traffic Count Data: {file}\")\n",
    "            traffic_df = pd.read_csv(os.path.join(traffic_path, file), encoding='ISO-8859-8')\n",
    "            print(\"Traffic Count Data Columns:\")\n",
    "            print(traffic_df.columns)\n",
    "            print(traffic_df.head())\n",
    "            print(\"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Traffic count data folder not found for year {year}\")\n",
    "\n",
    "# List of years to check\n",
    "years = ['2014', '2015', '2016', '2017', '2018', '2020', '2021']\n",
    "\n",
    "# Check the structure for each year\n",
    "for year in years:\n",
    "    check_data_structure(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'kvish1',\n",
      "       'kvish2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA', 'hodesh',\n",
      "       'shaa', 'SUG_YOM', 'YOM_LAYLA', 'yom_bashavua', 'humrat_teuna',\n",
      "       'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL', 'MEHIRUT_MUTERET', 'TKINUT',\n",
      "       'ROHAV', 'SIMUN_TIMRUR', 'TEURA', 'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM',\n",
      "       'MERHAK_EZEM', 'LO_HAZA', 'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA',\n",
      "       'MAHOZ', 'NAFA', 'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV',\n",
      "       'STATUS_IGUN', 'x_coord', 'y_coord'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2014000001        1              1          1          7400   303.0   \n",
      "1     2014000002        1              1          2          2650   390.0   \n",
      "2     2014000003        1              1          4             0     NaN   \n",
      "3     2014000004        1              1          1          5000  1555.0   \n",
      "4     2014000006        1              1          2          7600   505.0   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  kvish1  ...  MEKOM_HAZIYA  KIVUN_HAZIYA  \\\n",
      "0   306.0     NaN     260021.0     NaN  ...             3             1   \n",
      "1     NaN  9999.0          NaN     NaN  ...             3             9   \n",
      "2     NaN     NaN          NaN    20.0  ...             2             2   \n",
      "3  1511.0     NaN   11920611.0     NaN  ...             3             1   \n",
      "4     NaN    19.0          NaN     NaN  ...             3             1   \n",
      "\n",
      "   MAHOZ  NAFA  EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN  \\\n",
      "0      4    41        411                0.0           13            1   \n",
      "1      5    51        511                0.0           16            3   \n",
      "2      5    53        513               99.0           99            1   \n",
      "3      5    51        511                0.0           13            1   \n",
      "4      2    24        246                0.0           16            1   \n",
      "\n",
      "    x_coord   y_coord  \n",
      "0  187117.0  693833.0  \n",
      "1  185113.0  672015.0  \n",
      "2  177520.0  659502.0  \n",
      "3  179727.0  663713.0  \n",
      "4  207503.0  759266.0  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "def standardize_accident_columns(df):\n",
    "    column_mapping = {\n",
    "        'HODESH_TEUNA': 'hodesh',\n",
    "        'SHAA': 'shaa',\n",
    "        'YOM_BASHAVUA': 'yom_bashavua',\n",
    "        'HUMRAT_TEUNA': 'humrat_teuna',\n",
    "        'KVISH1': 'kvish1',\n",
    "        'KVISH2': 'kvish2',\n",
    "        'X': 'x_coord',\n",
    "        'Y': 'y_coord',\n",
    "        # Add more mappings if necessary based on your data inspection\n",
    "    }\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Test the function on one of the accident files\n",
    "sample_year = '2014'\n",
    "accident_sample_path = os.path.join(base_dir, sample_year, 'accidents', 'H20141332Accdatamekuzar.csv')\n",
    "accident_sample_df = pd.read_csv(accident_sample_path, encoding='ISO-8859-8')\n",
    "\n",
    "# Standardize the column names\n",
    "standardized_accident_df = standardize_accident_columns(accident_sample_df)\n",
    "\n",
    "# Display the standardized columns\n",
    "print(standardized_accident_df.columns)\n",
    "print(standardized_accident_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'kvish1',\n",
      "       'kvish2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA', 'hodesh',\n",
      "       'shaa', 'SUG_YOM', 'YOM_LAYLA', 'yom_bashavua', 'humrat_teuna',\n",
      "       'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL', 'MEHIRUT_MUTERET', 'TKINUT',\n",
      "       'ROHAV', 'SIMUN_TIMRUR', 'TEURA', 'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM',\n",
      "       'MERHAK_EZEM', 'LO_HAZA', 'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA',\n",
      "       'MAHOZ', 'NAFA', 'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV',\n",
      "       'STATUS_IGUN', 'x_coord', 'y_coord', 'year', 'MS_TAVLA', 'KOD', 'TEUR'],\n",
      "      dtype='object')\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0   2.014000e+09      1.0            1.0        1.0        7400.0   303.0   \n",
      "1   2.014000e+09      1.0            1.0        2.0        2650.0   390.0   \n",
      "2   2.014000e+09      1.0            1.0        4.0           0.0     NaN   \n",
      "3   2.014000e+09      1.0            1.0        1.0        5000.0  1555.0   \n",
      "4   2.014000e+09      1.0            1.0        2.0        7600.0   505.0   \n",
      "\n",
      "   REHOV2   BAYIT  ZOMET_IRONI  kvish1  ...  EZOR_TIVI  MAAMAD_MINIZIPALI  \\\n",
      "0   306.0     NaN     260021.0     NaN  ...      411.0                0.0   \n",
      "1     NaN  9999.0          NaN     NaN  ...      511.0                0.0   \n",
      "2     NaN     NaN          NaN    20.0  ...      513.0               99.0   \n",
      "3  1511.0     NaN   11920611.0     NaN  ...      511.0                0.0   \n",
      "4     NaN    19.0          NaN     NaN  ...      246.0                0.0   \n",
      "\n",
      "   ZURAT_ISHUV  STATUS_IGUN   x_coord   y_coord  year  MS_TAVLA  KOD  TEUR  \n",
      "0         13.0          1.0  187117.0  693833.0  2014       NaN  NaN   NaN  \n",
      "1         16.0          3.0  185113.0  672015.0  2014       NaN  NaN   NaN  \n",
      "2         99.0          1.0  177520.0  659502.0  2014       NaN  NaN   NaN  \n",
      "3         13.0          1.0  179727.0  663713.0  2014       NaN  NaN   NaN  \n",
      "4         16.0          1.0  207503.0  759266.0  2014       NaN  NaN   NaN  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "(92887, 49)\n"
     ]
    }
   ],
   "source": [
    "# List of years to process\n",
    "years = ['2014', '2015', '2016', '2017', '2018', '2020', '2021']\n",
    "\n",
    "# Initialize an empty list to hold the standardized DataFrames\n",
    "accident_dfs = []\n",
    "\n",
    "# Loop through each year and process the accident data\n",
    "for year in years:\n",
    "    # Define the path to the accident data for the current year\n",
    "    accident_path = os.path.join(base_dir, year, 'accidents')\n",
    "    \n",
    "    try:\n",
    "        # Get all CSV files in the accident directory\n",
    "        accident_files = [f for f in os.listdir(accident_path) if f.endswith('.csv')]\n",
    "        \n",
    "        for file in accident_files:\n",
    "            # Load the accident data\n",
    "            accident_df = pd.read_csv(os.path.join(accident_path, file), encoding='ISO-8859-8')\n",
    "            \n",
    "            # Standardize the column names\n",
    "            standardized_accident_df = standardize_accident_columns(accident_df)\n",
    "            \n",
    "            # Add a column for the year\n",
    "            standardized_accident_df['year'] = year\n",
    "            \n",
    "            # Append the standardized DataFrame to the list\n",
    "            accident_dfs.append(standardized_accident_df)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Accident data folder not found for year {year}\")\n",
    "\n",
    "# Concatenate all standardized DataFrames into one\n",
    "combined_accident_df = pd.concat(accident_dfs, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to ensure everything looks good\n",
    "print(combined_accident_df.columns)\n",
    "print(combined_accident_df.head())\n",
    "print(combined_accident_df.shape)  # Check the size of the combined DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize traffic count columns\n",
    "def standardize_traffic_columns(df):\n",
    "    column_mapping = {\n",
    "        'shana': 'year',\n",
    "        'kvish': 'kvish',\n",
    "        'keta': 'keta',\n",
    "        'maslul': 'maslul',\n",
    "        'hodesh': 'hodesh',\n",
    "        'taarich': 'taarich',\n",
    "        'yom': 'yom',\n",
    "        'shaa': 'shaa',\n",
    "        'nefah': 'kamut_kle_rehev',  # Assuming 'nefah' is the traffic count\n",
    "        'status': 'status_reshuma',\n",
    "        # Add any additional mappings needed to standardize columns across different years\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize accident data columns\n",
    "def standardize_accident_columns(df):\n",
    "    column_mapping = {\n",
    "        'pk_teuna_fikt': 'pk_teuna_fikt',\n",
    "        'sug_tik': 'sug_tik',\n",
    "        'THUM_GEOGRAFI': 'THUM_GEOGRAFI',\n",
    "        'SUG_DEREH': 'SUG_DEREH',\n",
    "        'SEMEL_YISHUV': 'SEMEL_YISHUV',\n",
    "        'REHOV1': 'REHOV1',\n",
    "        'REHOV2': 'REHOV2',\n",
    "        'BAYIT': 'BAYIT',\n",
    "        'ZOMET_IRONI': 'ZOMET_IRONI',\n",
    "        'kvish1': 'kvish1',\n",
    "        'kvish2': 'kvish2',\n",
    "        'KM': 'KM',\n",
    "        'ZOMET_LO_IRONI': 'ZOMET_LO_IRONI',\n",
    "        'YEHIDA': 'YEHIDA',\n",
    "        'SHNAT_TEUNA': 'SHNAT_TEUNA',\n",
    "        'hodesh': 'hodesh',\n",
    "        'shaa': 'shaa',\n",
    "        'SUG_YOM': 'SUG_YOM',\n",
    "        'YOM_LAYLA': 'YOM_LAYLA',\n",
    "        'yom_bashavua': 'yom_bashavua',\n",
    "        'humrat_teuna': 'humrat_teuna',\n",
    "        'SUG_TEUNA': 'SUG_TEUNA',\n",
    "        'HAD_MASLUL': 'HAD_MASLUL',\n",
    "        'RAV_MASLUL': 'RAV_MASLUL',\n",
    "        'MEHIRUT_MUTERET': 'MEHIRUT_MUTERET',\n",
    "        'TKINUT': 'TKINUT',\n",
    "        'ROHAV': 'ROHAV',\n",
    "        'SIMUN_TIMRUR': 'SIMUN_TIMRUR',\n",
    "        'TEURA': 'TEURA',\n",
    "        'MEZEG_AVIR': 'MEZEG_AVIR',\n",
    "        'PNE_KVISH': 'PNE_KVISH',\n",
    "        'SUG_EZEM': 'SUG_EZEM',\n",
    "        'MERHAK_EZEM': 'MERHAK_EZEM',\n",
    "        'LO_HAZA': 'LO_HAZA',\n",
    "        'OFEN_HAZIYA': 'OFEN_HAZIYA',\n",
    "        'MEKOM_HAZIYA': 'MEKOM_HAZIYA',\n",
    "        'KIVUN_HAZIYA': 'KIVUN_HAZIYA',\n",
    "        'MAHOZ': 'MAHOZ',\n",
    "        'NAFA': 'NAFA',\n",
    "        'EZOR_TIVI': 'EZOR_TIVI',\n",
    "        'MAAMAD_MINIZIPALI': 'MAAMAD_MINIZIPALI',\n",
    "        'ZURAT_ISHUV': 'ZURAT_ISHUV',\n",
    "        'STATUS_IGUN': 'STATUS_IGUN',\n",
    "        'x_coord': 'X',\n",
    "        'y_coord': 'Y',\n",
    "        'year': 'year',\n",
    "        'MS_TAVLA': 'MS_TAVLA',\n",
    "        'KOD': 'KOD',\n",
    "        'TEUR': 'TEUR',\n",
    "        # Add any additional mappings needed\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Accident Data:\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2020031644        1              1          1          1061   159.0   \n",
      "1     2020079871        1              1          4             0     NaN   \n",
      "2     2020081980        1              1          1          3000  1105.0   \n",
      "3     2021000007        1              1          1          4000  1394.0   \n",
      "4     2021000010        1              1          3             0     NaN   \n",
      "\n",
      "   REHOV2  BAYIT  ZOMET_IRONI  kvish1  ...  KIVUN_HAZIYA  MAHOZ  NAFA  \\\n",
      "0   275.0    NaN    7840004.0     NaN  ...             1      2    23   \n",
      "1     NaN    NaN          NaN  8966.0  ...             9      2    21   \n",
      "2  1307.0    NaN   26640236.0     NaN  ...             9      1    11   \n",
      "3  1391.0    NaN   17000742.0     NaN  ...             9      3    31   \n",
      "4     NaN    NaN          NaN    89.0  ...             9      2    45   \n",
      "\n",
      "   EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN         X         Y  \\\n",
      "0        237                0.0           16            1  230441.0  734148.0   \n",
      "1        212               99.0           99            1  245802.0  772308.0   \n",
      "2        111                0.0           12            1  218356.0  629343.0   \n",
      "3        311                0.0           13            1  201379.0  742666.0   \n",
      "4        245               99.0           99            1  216335.0  768965.0   \n",
      "\n",
      "   year  \n",
      "0  2021  \n",
      "1  2021  \n",
      "2  2021  \n",
      "3  2021  \n",
      "4  2021  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "Index(['pk_teuna_fikt', 'sug_tik', 'THUM_GEOGRAFI', 'SUG_DEREH',\n",
      "       'SEMEL_YISHUV', 'REHOV1', 'REHOV2', 'BAYIT', 'ZOMET_IRONI', 'kvish1',\n",
      "       'kvish2', 'KM', 'ZOMET_LO_IRONI', 'YEHIDA', 'SHNAT_TEUNA', 'hodesh',\n",
      "       'shaa', 'SUG_YOM', 'YOM_LAYLA', 'yom_bashavua', 'humrat_teuna',\n",
      "       'SUG_TEUNA', 'HAD_MASLUL', 'RAV_MASLUL', 'MEHIRUT_MUTERET', 'TKINUT',\n",
      "       'ROHAV', 'SIMUN_TIMRUR', 'TEURA', 'MEZEG_AVIR', 'PNE_KVISH', 'SUG_EZEM',\n",
      "       'MERHAK_EZEM', 'LO_HAZA', 'OFEN_HAZIYA', 'MEKOM_HAZIYA', 'KIVUN_HAZIYA',\n",
      "       'MAHOZ', 'NAFA', 'EZOR_TIVI', 'MAAMAD_MINIZIPALI', 'ZURAT_ISHUV',\n",
      "       'STATUS_IGUN', 'X', 'Y', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Apply the standardization function to the accident data\n",
    "standardized_accident_df = standardize_accident_columns(accident_df)\n",
    "\n",
    "# Display the standardized DataFrame\n",
    "print(\"Standardized Accident Data:\")\n",
    "print(standardized_accident_df.head())\n",
    "print(standardized_accident_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Accident Data:\n",
      "   pk_teuna_fikt  sug_tik  THUM_GEOGRAFI  SUG_DEREH  SEMEL_YISHUV  REHOV1  \\\n",
      "0     2020031644        1              1          1          1061   159.0   \n",
      "1     2020079871        1              1          4             0     NaN   \n",
      "2     2020081980        1              1          1          3000  1105.0   \n",
      "3     2021000007        1              1          1          4000  1394.0   \n",
      "4     2021000010        1              1          3             0     NaN   \n",
      "\n",
      "   REHOV2  BAYIT  ZOMET_IRONI  kvish1  ...  KIVUN_HAZIYA  MAHOZ  NAFA  \\\n",
      "0   275.0    NaN    7840004.0     NaN  ...             1      2    23   \n",
      "1     NaN    NaN          NaN  8966.0  ...             9      2    21   \n",
      "2  1307.0    NaN   26640236.0     NaN  ...             9      1    11   \n",
      "3  1391.0    NaN   17000742.0     NaN  ...             9      3    31   \n",
      "4     NaN    NaN          NaN    89.0  ...             9      2    45   \n",
      "\n",
      "   EZOR_TIVI  MAAMAD_MINIZIPALI  ZURAT_ISHUV  STATUS_IGUN         X         Y  \\\n",
      "0        237                0.0           16            1  230441.0  734148.0   \n",
      "1        212               99.0           99            1  245802.0  772308.0   \n",
      "2        111                0.0           12            1  218356.0  629343.0   \n",
      "3        311                0.0           13            1  201379.0  742666.0   \n",
      "4        245               99.0           99            1  216335.0  768965.0   \n",
      "\n",
      "   year  \n",
      "0  2021  \n",
      "1  2021  \n",
      "2  2021  \n",
      "3  2021  \n",
      "4  2021  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "(11554, 46)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_accident_data = pd.DataFrame()\n",
    "\n",
    "# Concatenate the standardized data to the combined DataFrame\n",
    "combined_accident_data = pd.concat([combined_accident_data, standardized_accident_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to ensure it was appended correctly\n",
    "print(\"Combined Accident Data:\")\n",
    "print(combined_accident_data.head())\n",
    "print(combined_accident_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2014...\n",
      "Processing data for year 2015...\n",
      "Processing data for year 2016...\n",
      "Processing data for year 2017...\n",
      "Processing data for year 2018...\n",
      "Processing data for year 2020...\n",
      "Processing data for year 2021...\n",
      "Combined Accident Data from All Years:\n",
      "   pk_teuna_fikt  sug_tik  thum_geografi  sug_dereh  semel_yishuv  rehov1  \\\n",
      "0   2.014000e+09      1.0            1.0        1.0        7400.0   303.0   \n",
      "1   2.014000e+09      1.0            1.0        2.0        2650.0   390.0   \n",
      "2   2.014000e+09      1.0            1.0        4.0           0.0     NaN   \n",
      "3   2.014000e+09      1.0            1.0        1.0        5000.0  1555.0   \n",
      "4   2.014000e+09      1.0            1.0        2.0        7600.0   505.0   \n",
      "\n",
      "   rehov2   bayit  zomet_ironi  kvish1  ...  ezor_tivi  maamad_minizipali  \\\n",
      "0   306.0     NaN     260021.0     NaN  ...      411.0                0.0   \n",
      "1     NaN  9999.0          NaN     NaN  ...      511.0                0.0   \n",
      "2     NaN     NaN          NaN    20.0  ...      513.0               99.0   \n",
      "3  1511.0     NaN   11920611.0     NaN  ...      511.0                0.0   \n",
      "4     NaN    19.0          NaN     NaN  ...      246.0                0.0   \n",
      "\n",
      "   zurat_ishuv  status_igun         x         y  year  ms_tavla  kod  teur  \n",
      "0         13.0          1.0  187117.0  693833.0  2014       NaN  NaN   NaN  \n",
      "1         16.0          3.0  185113.0  672015.0  2014       NaN  NaN   NaN  \n",
      "2         99.0          1.0  177520.0  659502.0  2014       NaN  NaN   NaN  \n",
      "3         13.0          1.0  179727.0  663713.0  2014       NaN  NaN   NaN  \n",
      "4         16.0          1.0  207503.0  759266.0  2014       NaN  NaN   NaN  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "(92887, 49)\n"
     ]
    }
   ],
   "source": [
    "# List of years to include in the combined dataset\n",
    "years = ['2014', '2015', '2016', '2017', '2018', '2020', '2021']\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_accident_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each year and process the data\n",
    "for year in years:\n",
    "    print(f\"Processing data for year {year}...\")\n",
    "    \n",
    "    # Load the standardized data for the current year (using the same standardization steps)\n",
    "    accident_path = os.path.join(base_dir, year, 'accidents')\n",
    "    \n",
    "    # Assuming each year has a similar file structure and column names\n",
    "    accident_files = [f for f in os.listdir(accident_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for file in accident_files:\n",
    "        accident_df = pd.read_csv(os.path.join(accident_path, file), encoding='ISO-8859-8')\n",
    "        \n",
    "        # Standardize the column names and add the year\n",
    "        standardized_accident_df = accident_df.rename(columns=str.lower).copy()\n",
    "        standardized_accident_df['year'] = int(year)\n",
    "        \n",
    "        # Append the standardized data to the combined DataFrame\n",
    "        combined_accident_data = pd.concat([combined_accident_data, standardized_accident_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to ensure all data was appended correctly\n",
    "print(\"Combined Accident Data from All Years:\")\n",
    "print(combined_accident_data.head())\n",
    "print(combined_accident_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined accident data saved to c:\\Users\\mousa\\Desktop\\College\\SHANA DALET\\GIS\\FINAL PROJECT GIT\\QGIS-Traffic-Accidents-IL\\DATA\\combined_accident_data1.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output path for the combined data\n",
    "output_path = os.path.join(base_dir, 'combined_accident_data1.csv')\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "combined_accident_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Combined accident data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE HAVE ALL THE YEARS ACCIDENT DATA IN ONE FILE NOW WE NEED TO PROCEED WITH DOING THE SAME FOR THE TRAFFIC COUNTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic Counts 2014:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2014      1    10       1       9        7    1     0   1936     NaN\n",
      "1   2014      1    10       1       9        7    1     1    966     NaN\n",
      "2   2014      1    10       1       9        7    1     2    737     NaN\n",
      "3   2014      1    10       1       9        7    1     3    596     NaN\n",
      "4   2014      1    10       1       9        7    1     4    479     NaN\n",
      "\n",
      "Traffic Counts 2015:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2015      1    10       1       6       15    2     0   1346     NaN\n",
      "1   2015      1    10       1       6       15    2     1    788     NaN\n",
      "2   2015      1    10       1       6       15    2     2    626     NaN\n",
      "3   2015      1    10       1       6       15    2     3    652     NaN\n",
      "4   2015      1    10       1       6       15    2     4    597     NaN\n",
      "\n",
      "Traffic Counts 2016:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2016      1    10       1       9       11    1     0   1710     NaN\n",
      "1   2016      1    10       1       9       11    1     1    934     NaN\n",
      "2   2016      1    10       1       9       11    1     2    800     NaN\n",
      "3   2016      1    10       1       9       11    1     3    637     NaN\n",
      "4   2016      1    10       1       9       11    1     4    588     NaN\n",
      "\n",
      "Traffic Counts 2017:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2017      1    52       1       2        5    1     0    839     NaN\n",
      "1   2017      1    52       1       2        5    1     1    459     NaN\n",
      "2   2017      1    52       1       2        5    1     2    338     NaN\n",
      "3   2017      1    52       1       2        5    1     3    318     NaN\n",
      "4   2017      1    52       1       2        5    1     4    403     NaN\n",
      "\n",
      "Traffic Counts 2018:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  nefah  status\n",
      "0   2018      1    54       1       6       14    5     0   1018     NaN\n",
      "1   2018      1    54       1       6       14    5     1    814     NaN\n",
      "2   2018      1    54       1       6       14    5     2    450     NaN\n",
      "3   2018      1    54       1       6       14    5     3    415     NaN\n",
      "4   2018      1    54       1       6       14    5     4    471     NaN\n",
      "\n",
      "Traffic Counts 2020:\n",
      "   shana  kvish  keta  maslul  hodesh  taarich  yom  shaa  kamut  status\n",
      "0   2020      1    20       1      12        2    4     0   1123     NaN\n",
      "1   2020      1    20       1      12        2    4     1    557     NaN\n",
      "2   2020      1    20       1      12        2    4     2    376     NaN\n",
      "3   2020      1    20       1      12        2    4     3    300     NaN\n",
      "4   2020      1    20       1      12        2    4     4    376     NaN\n",
      "\n",
      "Traffic Counts 2021:\n",
      "   shnat_seker  kvish  keta  maslul  hodesh  yom  yom_bashavua  shaa  \\\n",
      "0       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   0.0   \n",
      "1       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   1.0   \n",
      "2       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   2.0   \n",
      "3       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   3.0   \n",
      "4       2021.0    1.0  20.0     1.0     7.0  6.0           3.0   4.0   \n",
      "\n",
      "   kamut_kle_rehev  status_reshuma  \n",
      "0           1486.0             NaN  \n",
      "1           1170.0             NaN  \n",
      "2            795.0             NaN  \n",
      "3            601.0             NaN  \n",
      "4           1134.0             NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory where the data is stored\n",
    "base_dir = '../'\n",
    "\n",
    "# Load the traffic count data for each year\n",
    "traffic_counts_2014 = pd.read_csv(os.path.join(base_dir, '2014/count/2014109h1tabmef.csv'))\n",
    "traffic_counts_2015 = pd.read_csv(os.path.join(base_dir, '2015/count/H20151091TabMef_1.csv'))\n",
    "traffic_counts_2016 = pd.read_csv(os.path.join(base_dir, '2016/count/H20161091TabMef.csv'))\n",
    "traffic_counts_2017 = pd.read_csv(os.path.join(base_dir, '2017/count/h20171092tabmef.csv'))\n",
    "traffic_counts_2018 = pd.read_csv(os.path.join(base_dir, '2018/count/2018109H1TabMef.csv'))\n",
    "traffic_counts_2020 = pd.read_csv(os.path.join(base_dir, '2020/count/H20201091/H20201091TabMef.csv'))\n",
    "traffic_counts_2021 = pd.read_csv(os.path.join(base_dir, '2021/count/H20211092TabMef.csv'))\n",
    "\n",
    "# Inspect the first few rows of each traffic count dataset to understand their structure\n",
    "print(\"Traffic Counts 2014:\")\n",
    "print(traffic_counts_2014.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2015:\")\n",
    "print(traffic_counts_2015.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2016:\")\n",
    "print(traffic_counts_2016.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2017:\")\n",
    "print(traffic_counts_2017.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2018:\")\n",
    "print(traffic_counts_2018.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2020:\")\n",
    "print(traffic_counts_2020.head())\n",
    "\n",
    "print(\"\\nTraffic Counts 2021:\")\n",
    "print(traffic_counts_2021.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Traffic Count Data:\n",
      "     year  kvish  keta  maslul  hodesh  taarich  yom  shaa  kamut_kle_rehev  \\\n",
      "0  2014.0    1.0  10.0     1.0     9.0      7.0  1.0   0.0           1936.0   \n",
      "1  2014.0    1.0  10.0     1.0     9.0      7.0  1.0   1.0            966.0   \n",
      "2  2014.0    1.0  10.0     1.0     9.0      7.0  1.0   2.0            737.0   \n",
      "3  2014.0    1.0  10.0     1.0     9.0      7.0  1.0   3.0            596.0   \n",
      "4  2014.0    1.0  10.0     1.0     9.0      7.0  1.0   4.0            479.0   \n",
      "\n",
      "   status_reshuma  yom_bashavua  \n",
      "0             NaN           NaN  \n",
      "1             NaN           NaN  \n",
      "2             NaN           NaN  \n",
      "3             NaN           NaN  \n",
      "4             NaN           NaN  \n",
      "(866881, 11)\n"
     ]
    }
   ],
   "source": [
    "# Function to standardize traffic count columns\n",
    "def standardize_traffic_columns(df):\n",
    "    column_mapping = {\n",
    "        'shana': 'year',\n",
    "        'shnat_seker': 'year',\n",
    "        'kvish': 'kvish',\n",
    "        'keta': 'keta',\n",
    "        'maslul': 'maslul',\n",
    "        'hodesh': 'hodesh',\n",
    "        'taarich': 'taarich',\n",
    "        'yom': 'yom',\n",
    "        'shaa': 'shaa',\n",
    "        'nefah': 'kamut_kle_rehev',  # Assuming 'nefah' represents traffic count\n",
    "        'kamut': 'kamut_kle_rehev',\n",
    "        'kamut_kle_rehev': 'kamut_kle_rehev',\n",
    "        'status': 'status_reshuma',\n",
    "        'status_reshuma': 'status_reshuma',\n",
    "        # Add any other mappings necessary\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n",
    "\n",
    "# Standardize each dataset\n",
    "traffic_counts_2014 = standardize_traffic_columns(traffic_counts_2014)\n",
    "traffic_counts_2015 = standardize_traffic_columns(traffic_counts_2015)\n",
    "traffic_counts_2016 = standardize_traffic_columns(traffic_counts_2016)\n",
    "traffic_counts_2017 = standardize_traffic_columns(traffic_counts_2017)\n",
    "traffic_counts_2018 = standardize_traffic_columns(traffic_counts_2018)\n",
    "traffic_counts_2020 = standardize_traffic_columns(traffic_counts_2020)\n",
    "traffic_counts_2021 = standardize_traffic_columns(traffic_counts_2021)\n",
    "\n",
    "# Concatenate all standardized traffic count data into one DataFrame\n",
    "combined_traffic_counts = pd.concat([\n",
    "    traffic_counts_2014,\n",
    "    traffic_counts_2015,\n",
    "    traffic_counts_2016,\n",
    "    traffic_counts_2017,\n",
    "    traffic_counts_2018,\n",
    "    traffic_counts_2020,\n",
    "    traffic_counts_2021\n",
    "], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame to ensure it was appended correctly\n",
    "print(\"Combined Traffic Count Data:\")\n",
    "print(combined_traffic_counts.head())\n",
    "print(combined_traffic_counts.shape)  # Check the size of the combined DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANAGING MISSING DATA(yom bashuva)\n",
    "by calculating it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year  hodesh  taarich  yom_bashavua\n",
      "0      2014.0     9.0      7.0           1.0\n",
      "24     2014.0     9.0      8.0           2.0\n",
      "48     2014.0     9.0      9.0           3.0\n",
      "72     2014.0     9.0     10.0           4.0\n",
      "96     2014.0     9.0     11.0           5.0\n",
      "...       ...     ...      ...           ...\n",
      "8520   2014.0    12.0     28.0           1.0\n",
      "8544   2014.0    12.0     29.0           2.0\n",
      "8568   2014.0    12.0     22.0           2.0\n",
      "13776  2014.0     4.0      4.0           6.0\n",
      "13800  2014.0     4.0      5.0           7.0\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate yom_bashavua with Sunday as 1, Monday as 2, ..., Saturday as 7\n",
    "def calculate_yom_bashavua(row):\n",
    "    try:\n",
    "        # Create a date object from year, month, and day\n",
    "        date = datetime(int(row['year']), int(row['hodesh']), int(row['taarich']))\n",
    "        # Adjust so Sunday=1, Monday=2, ..., Saturday=7\n",
    "        yom_bashavua = (date.weekday() + 1) % 7 + 1\n",
    "        return yom_bashavua\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "combined_traffic_counts['yom_bashavua'] = combined_traffic_counts.apply(calculate_yom_bashavua, axis=1)\n",
    "\n",
    "# Display the dataframe with the newly calculated yom_bashavua\n",
    "print(combined_traffic_counts[['year', 'hodesh', 'taarich', 'yom_bashavua']].drop_duplicates().head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Road Segments Data:\n",
      "   kvish  keta         X         Y\n",
      "1      1    52  193638.0  647061.0\n",
      "3      1    60  200817.0  636966.0\n",
      "4      2    70  192262.0  714572.0\n",
      "5      2    80  195812.0  734655.0\n",
      "6      3    10  163509.0  620663.0\n",
      "(2357, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory where your road segment data is stored\n",
    "base_dir = '../'\n",
    "\n",
    "# Load road segment data with coordinates, specifying the encoding\n",
    "road_segments_2016 = pd.read_csv(os.path.join(base_dir, '2016/count/H20161091RoadsNonUrban.csv'), encoding='ISO-8859-8')\n",
    "road_segments_2017 = pd.read_csv(os.path.join(base_dir, '2017/count/h20171092roadsnonurban.csv'), encoding='ISO-8859-8')\n",
    "road_segments_2018 = pd.read_excel(os.path.join(base_dir, '2018/count/H20181091RoadsNonUrban.xls'))\n",
    "road_segments_2020 = pd.read_excel(os.path.join(base_dir, '2020/count/H20201091RoadsNonUrban.xls'))\n",
    "road_segments_2021 = pd.read_excel(os.path.join(base_dir, '2021/count/H20211092RoadsNonUrban.xls'))\n",
    "\n",
    "# Function to standardize road segment columns\n",
    "def standardize_road_segment_columns(df):\n",
    "    column_mapping = {\n",
    "        'כביש': 'kvish',\n",
    "        'קטע': 'keta',\n",
    "        'ק\"מ מ-': 'km_start',\n",
    "        'שם מ-': 'name_start',\n",
    "        'ק\"מ עד': 'km_end',\n",
    "        'שם עד': 'name_end',\n",
    "        'ק\"מ הצבה': 'km_mark',\n",
    "        'X של מקום ההצבה': 'X',\n",
    "        'Y של מקום ההצבה': 'Y',\n",
    "        'x': 'X',\n",
    "        'y': 'Y'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df[['kvish', 'keta', 'X', 'Y']]  # Keep only relevant columns\n",
    "\n",
    "# Standardize and concatenate the data (excluding 2015)\n",
    "road_segments_2016 = standardize_road_segment_columns(road_segments_2016)\n",
    "road_segments_2017 = standardize_road_segment_columns(road_segments_2017)\n",
    "road_segments_2018 = standardize_road_segment_columns(road_segments_2018)\n",
    "road_segments_2020 = standardize_road_segment_columns(road_segments_2020)\n",
    "road_segments_2021 = standardize_road_segment_columns(road_segments_2021)\n",
    "\n",
    "# Concatenate the data into a single DataFrame\n",
    "combined_road_segments = pd.concat([\n",
    "    road_segments_2016,\n",
    "    road_segments_2017,\n",
    "    road_segments_2018,\n",
    "    road_segments_2020,\n",
    "    road_segments_2021\n",
    "], ignore_index=True)\n",
    "combined_road_segments = combined_road_segments.dropna(subset=['X', 'Y'])\n",
    "\n",
    "# Display the combined DataFrame to ensure everything is correct\n",
    "print(\"Combined Road Segments Data:\")\n",
    "print(combined_road_segments.head())\n",
    "print(combined_road_segments.shape)  # Check the size of the combined DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Traffic Count Data with Coordinates:\n",
      "     year  kvish  keta  maslul  hodesh  taarich  yom  shaa  kamut_kle_rehev  \\\n",
      "0  2016.0    1.0  52.0     1.0     9.0     11.0  1.0   0.0           1134.0   \n",
      "1  2016.0    1.0  52.0     1.0     9.0     11.0  1.0   1.0            630.0   \n",
      "2  2016.0    1.0  52.0     1.0     9.0     11.0  1.0   2.0            500.0   \n",
      "3  2016.0    1.0  52.0     1.0     9.0     11.0  1.0   3.0            338.0   \n",
      "4  2016.0    1.0  52.0     1.0     9.0     11.0  1.0   4.0            392.0   \n",
      "\n",
      "   status_reshuma         X         Y  \n",
      "0             NaN  193638.0  647061.0  \n",
      "1             NaN  193638.0  647061.0  \n",
      "2             NaN  193638.0  647061.0  \n",
      "3             NaN  193638.0  647061.0  \n",
      "4             NaN  193638.0  647061.0  \n",
      "(621432, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory where your road segment data is stored\n",
    "base_dir = '../'\n",
    "\n",
    "# Load traffic count data\n",
    "traffic_counts = {\n",
    "    '2016': pd.read_csv(os.path.join(base_dir, '2016/count/H20161091TabMef.csv')),\n",
    "    '2017': pd.read_csv(os.path.join(base_dir, '2017/count/h20171092tabmef.csv')),\n",
    "    '2018': pd.read_csv(os.path.join(base_dir, '2018/count/2018109H1TabMef.csv')),\n",
    "    '2020': pd.read_csv(os.path.join(base_dir, '2020/count/H20201091TabMef.csv')),\n",
    "    '2021': pd.read_csv(os.path.join(base_dir, '2021/count/H20211092TabMef.csv')),\n",
    "}\n",
    "\n",
    "# Load road segment data\n",
    "road_segments = {\n",
    "    '2016': pd.read_csv(os.path.join(base_dir, '2016/count/H20161091RoadsNonUrban.csv'), encoding='ISO-8859-8'),\n",
    "    '2017': pd.read_csv(os.path.join(base_dir, '2017/count/h20171092roadsnonurban.csv'), encoding='ISO-8859-8'),\n",
    "    '2018': pd.read_excel(os.path.join(base_dir, '2018/count/H20181091RoadsNonUrban.xls')),\n",
    "    '2020': pd.read_excel(os.path.join(base_dir, '2020/count/H20201091RoadsNonUrban.xls')),\n",
    "    '2021': pd.read_excel(os.path.join(base_dir, '2021/count/H20211092RoadsNonUrban.xls')),\n",
    "}\n",
    "\n",
    "# Function to standardize road segment columns\n",
    "def standardize_road_segment_columns(df):\n",
    "    column_mapping = {\n",
    "        'כביש': 'kvish',\n",
    "        'קטע': 'keta',\n",
    "        'X של מקום ההצבה': 'X',\n",
    "        'Y של מקום ההצבה': 'Y',\n",
    "        'x': 'X',\n",
    "        'y': 'Y'\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df[['kvish', 'keta', 'X', 'Y']]\n",
    "\n",
    "# Function to standardize traffic count columns\n",
    "def standardize_traffic_columns(df):\n",
    "    column_mapping = {\n",
    "        'shana': 'year',\n",
    "        'shnat_seker': 'year',\n",
    "        'kvish': 'kvish',\n",
    "        'keta': 'keta',\n",
    "        'maslul': 'maslul',\n",
    "        'hodesh': 'hodesh',\n",
    "        'taarich': 'taarich',\n",
    "        'yom': 'yom',\n",
    "        'yom_bashavua': 'yom',  # Standardize yom_bashavua to yom\n",
    "        'shaa': 'shaa',\n",
    "        'nefah': 'kamut_kle_rehev',  # Standardize nefah to kamut_kle_rehev\n",
    "        'kamut': 'kamut_kle_rehev',\n",
    "        'kamut_kle_rehev': 'kamut_kle_rehev',\n",
    "        'status': 'status_reshuma',\n",
    "        'status_reshuma': 'status_reshuma',\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    return df\n",
    "\n",
    "# Standardize road segment columns\n",
    "for year in road_segments:\n",
    "    road_segments[year] = standardize_road_segment_columns(road_segments[year])\n",
    "\n",
    "# Standardize traffic count columns\n",
    "for year in traffic_counts:\n",
    "    traffic_counts[year] = standardize_traffic_columns(traffic_counts[year])\n",
    "\n",
    "# Merge traffic counts with road segments for each year\n",
    "merged_traffic_counts = {}\n",
    "for year in traffic_counts:\n",
    "    merged_data = pd.merge(traffic_counts[year], road_segments[year], on=['kvish', 'keta'], how='left')\n",
    "    merged_data = merged_data.dropna(subset=['X', 'Y'])\n",
    "    merged_data = merged_data.reset_index(drop=True)  # Reset index to ensure unique index values\n",
    "    merged_traffic_counts[year] = merged_data\n",
    "\n",
    "# Check for duplicated columns and resolve them\n",
    "for year in merged_traffic_counts:\n",
    "    cols_to_drop = merged_traffic_counts[year].columns.duplicated(keep=False)\n",
    "    merged_traffic_counts[year] = merged_traffic_counts[year].loc[:, ~cols_to_drop]\n",
    "\n",
    "# Concatenate all years together\n",
    "combined_traffic_counts = pd.concat(merged_traffic_counts.values(), ignore_index=True)\n",
    "\n",
    "# Export the merged data to a CSV file\n",
    "output_path = os.path.join(base_dir, 'combined_traffic_counts_with_coordinates.csv')\n",
    "combined_traffic_counts.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the combined DataFrame to ensure everything is correct\n",
    "print(\"Combined Traffic Count Data with Coordinates:\")\n",
    "print(combined_traffic_counts.head())\n",
    "print(combined_traffic_counts.shape)  # Check the size of the combined DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
